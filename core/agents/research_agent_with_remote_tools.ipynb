{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "530ddf11-d6ef-43e2-a560-df08dc1e8652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f40af0da-5b59-49ff-b510-055c119728f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load the autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload to automatically reload all modules\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6363aa22-c3bf-4418-b26f-43dc4f0d7069",
   "metadata": {},
   "source": [
    "This notebook demostrate how llm uses functions in tools/remote_tools.py to ping user specify api and the get the expected answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71a49aa-0df2-4033-ba22-dff2a74e25b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname('__file__'), '../..')))\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from core.agents.tools.remote_tools import remote_tool_func, fetch_tools, remote_api_call,construct_url\n",
    "from langchain.agents import Tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo-0125\"\n",
    "TEMPERATURE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "768a19e0-1e80-4492-9a09-da91c70911de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `fetch_remote_tool` with `123`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'name': 'temperature_api', 'url': 'https://temperature/api?', 'params': {'key': 'whatever'}}, {'name': 'news', 'url': 'https://nytimes/api', 'params': 'whatever'}]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `construct_url` with `{\"name\": \"temperature_api\", \"url\": \"https://temperature/api?\", \"params\": {\"key\": \"whatever\"}}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mhttps://temperature/api?key=whatever\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ping_remote_api` with `https://temperature/api?key=whatever`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m{'temperature': 20}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `fetch_remote_tool` with `123`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'name': 'temperature_api', 'url': 'https://temperature/api?', 'params': {'key': 'whatever'}}, {'name': 'news', 'url': 'https://nytimes/api', 'params': 'whatever'}]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `fetch_remote_tool` with `123`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'name': 'temperature_api', 'url': 'https://temperature/api?', 'params': {'key': 'whatever'}}, {'name': 'news', 'url': 'https://nytimes/api', 'params': 'whatever'}]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `fetch_remote_tool` with `123`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'name': 'temperature_api', 'url': 'https://temperature/api?', 'params': {'key': 'whatever'}}, {'name': 'news', 'url': 'https://nytimes/api', 'params': 'whatever'}]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `construct_url` with `{\"name\": \"temperature_api\", \"url\": \"https://temperature/api?\", \"params\": {\"key\": \"whatever\"}}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mhttps://temperature/api?key=whatever\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ping_remote_api` with `https://temperature/api?key=whatever`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m{'temperature': 20}\u001b[0m\u001b[32;1m\u001b[1;3mThe current temperature is 20°C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent result: {'input': 'you have user_id 123. what is the temperature?', 'output': 'The current temperature is 20°C.'}\n"
     ]
    }
   ],
   "source": [
    "fetch_tool = Tool(\n",
    "    name=\"fetch_remote_tool\",\n",
    "    func=fetch_tools,\n",
    "    description=\"Fetch user registered remote tools by user id. Returns a list of tool dictionaries.\"\n",
    ")\n",
    "\n",
    "ping_tool = Tool(\n",
    "    name=\"ping_remote_api\",\n",
    "    func=remote_api_call,\n",
    "    description=\"Ping a constructed API URL and return the response.\"\n",
    ")\n",
    "\n",
    "construct_url_tool = Tool(\n",
    "    name=\"construct_url\",\n",
    "    func=construct_url,\n",
    "    description=\"Construct a full URL from a tool dictionary. Input must be a dictionary in the format {'name': string, 'url': string, 'params': dict}.\"\n",
    ")\n",
    "\n",
    "tools = [fetch_tool, ping_tool,construct_url_tool]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"You are a smart API assistant. \"\n",
    "     \"1. First, use 'fetch_remote_tool' with user_id to retrieve a list of tool dictionaries. \"\n",
    "     \"2. Then, select the correct tool (e.g., 'temperature_api'). \"\n",
    "     \"3. Pass the **entire tool dictionary** (not just the URL) to 'construct_url' to generate a full URL. \"\n",
    "     \"4. Finally, use 'ping_remote_api' with the fully constructed URL to get the API response. \"\n",
    "     \"Be sure to pass dictionaries, not strings, when constructing URLs.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{agent_scratchpad}\")\n",
    "])\n",
    "\n",
    "# model = ChatOllama(model=\"mistral-nemo\", temperature=0)\n",
    "model  = ChatOpenAI(\n",
    "    model=MODEL, \n",
    "    temperature=TEMPERATURE,\n",
    "    # base_url=\"http://host.docker.internal:11434\", # if running in the studio\n",
    "    )\n",
    "agent = create_openai_tools_agent(model, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "result = agent_executor.invoke({\"input\": \"you have user_id 123. what is the temperature?\"})\n",
    "\n",
    "print(f\"Agent result: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ad36e5-882b-4a8b-9639-3e5dbf2eb768",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
