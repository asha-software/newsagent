{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import importlib\n",
    "import os\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "\n",
    "MODEL = \"mistral-nemo\"\n",
    "TEMPERATURE = 0\n",
    "load_dotenv(\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools: ['multiply', 'add', 'divide', 'query']\n"
     ]
    }
   ],
   "source": [
    "TOOL_REGISTRY = {\n",
    "    \"tools.calculator\": [\"multiply\", \"add\", \"divide\"],\n",
    "    \"tools.wikipedia\": [\"query\"],\n",
    "}\n",
    "\n",
    "\n",
    "def import_function(module_name, function_name):\n",
    "    \"\"\"Dynamically imports a function from a module.\n",
    "\n",
    "    Args:\n",
    "        module_name: The name of the module (e.g., \"my_module\").\n",
    "        function_name: The name of the function to import (e.g., \"my_function\").\n",
    "\n",
    "    Returns:\n",
    "        The imported function, or None if the module or function is not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        module = importlib.import_module(module_name)\n",
    "        function = getattr(module, function_name)\n",
    "        return function\n",
    "    except (ImportError, AttributeError):\n",
    "        print(\n",
    "            f\"Error: Could not import function '{function_name}' from module '{module_name}'.\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "tools = [\n",
    "    import_function(module, function)\n",
    "    for module, functions in TOOL_REGISTRY.items()\n",
    "    for function in functions\n",
    "]\n",
    "print(f\"Tools: {[tool.__name__ for tool in tools]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=MODEL,\n",
    "    temperature=TEMPERATURE,\n",
    "    # base_url=\"http://host.docker.internal:11434\", # if running in the studio\n",
    ").bind_tools(tools)\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    claim: str\n",
    "    evidence: list[dict]  # {'name': tool name, 'args': {kwargs}, 'result': str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "with open(\"prompts/research_agent_system_prompt.txt\", \"r\") as f:\n",
    "    sys_msg = SystemMessage(content=f.read())\n",
    "\n",
    "\n",
    "def preprocessing(state: State):\n",
    "    \"\"\"\n",
    "    Preprocesses state before sending to the assistant for tool routing.\n",
    "    Currently, this just extracts the claim from the state and sets it as a HumanMessage\n",
    "    following the SystemMessage\n",
    "    \"\"\"\n",
    "    return {\"messages\": HumanMessage(content=state[\"claim\"])}\n",
    "\n",
    "\n",
    "def assistant(state: State) -> State:\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "def postprocessing(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Scan the message history to extract tool calls and results into tuples:\n",
    "    (tool_name, tool_args, tool_result) for the 'evidence' list in the state\n",
    "    \"\"\"\n",
    "\n",
    "    evidence = []\n",
    "    for i in range(len(state[\"messages\"])):\n",
    "        message = state[\"messages\"][i]\n",
    "        if isinstance(message, AIMessage) and hasattr(message, \"tool_calls\"):\n",
    "            for tool_call in message.tool_calls:\n",
    "                # Scan later messages for the corresponding ToolMessage\n",
    "                for j in range(i + 1, len(state[\"messages\"])):\n",
    "                    next_message = state[\"messages\"][j]\n",
    "                    if (\n",
    "                        isinstance(next_message, ToolMessage)\n",
    "                        and next_message.tool_call_id == tool_call[\"id\"]\n",
    "                    ):\n",
    "                        # Found the corresponding ToolMessage\n",
    "                        evidence.append(\n",
    "                            {\n",
    "                                \"name\": tool_call[\"name\"],\n",
    "                                \"args\": tool_call[\"args\"],\n",
    "                                \"result\": next_message.content,\n",
    "                            }\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "    return {\"evidence\": evidence}\n",
    "    # return state\n",
    "\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"preprocessing\", preprocessing)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_node(\"postprocessing\", postprocessing)\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"preprocessing\")\n",
    "builder.add_edge(\"preprocessing\", \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    source=\"assistant\",\n",
    "    path=tools_condition,\n",
    "    path_map={\"tools\": \"tools\", \"__end__\": \"postprocessing\"},\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "builder.add_edge(\"postprocessing\", END)\n",
    "\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Show\n",
    "# display(Image(react_graph.get_graph(xray=False).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.messages import HumanMessage, SystemMessage\n",
    "claim = \"1/3 is bigger than 1/4.\"\n",
    "# initial_state = {\"claim\": claim}\n",
    "# final_state = graph.invoke(initial_state)\n",
    "\n",
    "messages = [sys_msg]\n",
    "messages = react_graph.invoke({\"messages\": messages, \"claim\": claim})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are an **Evidence Retrieval Agent**. Your role is to retrieve supporting or contradictory evidence for a given claim using the tools available to you.  \n",
      "\n",
      "### **Rules:**  \n",
      "1. **Do Not Evaluate the Claim** â€“ Your task is to retrieve evidence, not to judge the claim's truth.  \n",
      "2. **Select and Use Tools Strategically** â€“ Based on the claim, think carefully which tools would help, and construct the correct tool calls to retrieve relevant evidence.  \n",
      "3. **Return Only Tool Messages** â€“ Your output should consist solely of tool calls with properly structured arguments. Do not generate natural language explanations.  \n",
      "4. **Handle Ambiguity Thoughtfully** â€“ If the claim is unclear, attempt a best-guess search or request clarification through a tool call if applicable.  \n",
      "5. **Retrieve Evidence from Multiple Perspectives** â€“ If conflicting evidence exists, return both supporting and contradictory sources.  \n",
      "\n",
      "### **Behavior:**  \n",
      "- Use available tools efficiently to retrieve the most relevant information.  \n",
      "- Use numeric tools such as calculators for numeric claims\n",
      "- Do not summarize, interpret, or filter the evidenceâ€”simply retrieve and present it through tool calls.  \n",
      "\n",
      "Your sole function is to query tools and return raw evidence. You do not form conclusions or engage in reasoning about the claim.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "1/3 is bigger than 1/4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  query (e5d05507-9826-4647-9c62-0485a24e75c5)\n",
      " Call ID: e5d05507-9826-4647-9c62-0485a24e75c5\n",
      "  Args:\n",
      "    query: Compare the sizes of fractions 1/3 and 1/4.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: query\n",
      "\n",
      "No Wikipedia page found for 'Compare the sizes of fractions 1/3 and 1/4.'.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To compare the sizes of two fractions, we can convert them to decimal form or find a common denominator.\n",
      "\n",
      "For 1/3:\n",
      "1 Ã· 3 = 0.333...\n",
      "\n",
      "For 1/4:\n",
      "1 Ã· 4 = 0.25\n",
      "\n",
      "Comparing these decimals, we see that 0.333... is greater than 0.25. Therefore, 1/3 is bigger than 1/4.\n"
     ]
    }
   ],
   "source": [
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'claim': '1/3 is bigger than 1/4.',\n",
      " 'evidence': [{'args': {'query': 'Compare the sizes of fractions 1/3 and 1/4.'},\n",
      "               'name': 'query',\n",
      "               'result': \"No Wikipedia page found for 'Compare the sizes of \"\n",
      "                         \"fractions 1/3 and 1/4.'.\"}],\n",
      " 'messages': [SystemMessage(content=\"You are an **Evidence Retrieval Agent**. Your role is to retrieve supporting or contradictory evidence for a given claim using the tools available to you.  \\n\\n### **Rules:**  \\n1. **Do Not Evaluate the Claim** â€“ Your task is to retrieve evidence, not to judge the claim's truth.  \\n2. **Select and Use Tools Strategically** â€“ Based on the claim, think carefully which tools would help, and construct the correct tool calls to retrieve relevant evidence.  \\n3. **Return Only Tool Messages** â€“ Your output should consist solely of tool calls with properly structured arguments. Do not generate natural language explanations.  \\n4. **Handle Ambiguity Thoughtfully** â€“ If the claim is unclear, attempt a best-guess search or request clarification through a tool call if applicable.  \\n5. **Retrieve Evidence from Multiple Perspectives** â€“ If conflicting evidence exists, return both supporting and contradictory sources.  \\n\\n### **Behavior:**  \\n- Use available tools efficiently to retrieve the most relevant information.  \\n- Use numeric tools such as calculators for numeric claims\\n- Do not summarize, interpret, or filter the evidenceâ€”simply retrieve and present it through tool calls.  \\n\\nYour sole function is to query tools and return raw evidence. You do not form conclusions or engage in reasoning about the claim.\", additional_kwargs={}, response_metadata={}, id='370548b9-e170-4163-9fbd-1ed011e734be'),\n",
      "              HumanMessage(content='1/3 is bigger than 1/4.', additional_kwargs={}, response_metadata={}, id='d042aa24-ad9b-4339-b5af-c69f002cbe21'),\n",
      "              AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'mistral-nemo', 'created_at': '2025-03-15T18:17:03.328178Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2344843000, 'load_duration': 27614750, 'prompt_eval_count': 547, 'prompt_eval_duration': 1509000000, 'eval_count': 33, 'eval_duration': 805000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-c85ce358-e334-4aee-8ee5-fa0c2e43f2d6-0', tool_calls=[{'name': 'query', 'args': {'query': 'Compare the sizes of fractions 1/3 and 1/4.'}, 'id': 'e5d05507-9826-4647-9c62-0485a24e75c5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 547, 'output_tokens': 33, 'total_tokens': 580}),\n",
      "              ToolMessage(content=\"No Wikipedia page found for 'Compare the sizes of fractions 1/3 and 1/4.'.\", name='query', id='dd7e1db8-9f8d-412e-96d6-bf28b3aec30b', tool_call_id='e5d05507-9826-4647-9c62-0485a24e75c5'),\n",
      "              AIMessage(content='To compare the sizes of two fractions, we can convert them to decimal form or find a common denominator.\\n\\nFor 1/3:\\n1 Ã· 3 = 0.333...\\n\\nFor 1/4:\\n1 Ã· 4 = 0.25\\n\\nComparing these decimals, we see that 0.333... is greater than 0.25. Therefore, 1/3 is bigger than 1/4.', additional_kwargs={}, response_metadata={'model': 'mistral-nemo', 'created_at': '2025-03-15T18:17:06.11906Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2590695208, 'load_duration': 31516291, 'prompt_eval_count': 76, 'prompt_eval_duration': 252000000, 'eval_count': 98, 'eval_duration': 2305000000, 'message': Message(role='assistant', content='To compare the sizes of two fractions, we can convert them to decimal form or find a common denominator.\\n\\nFor 1/3:\\n1 Ã· 3 = 0.333...\\n\\nFor 1/4:\\n1 Ã· 4 = 0.25\\n\\nComparing these decimals, we see that 0.333... is greater than 0.25. Therefore, 1/3 is bigger than 1/4.', images=None, tool_calls=None)}, id='run-34f137c7-c60a-48e3-ab5f-1b3494deeebc-0', usage_metadata={'input_tokens': 76, 'output_tokens': 98, 'total_tokens': 174})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content=\"No Wikipedia page found for 'Compare the sizes of fractions 1/3 and 1/4.'.\", name='query', id='dd7e1db8-9f8d-412e-96d6-bf28b3aec30b', tool_call_id='e5d05507-9826-4647-9c62-0485a24e75c5')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = react_graph.nodes[\"assistant\"].invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"hi there\")]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': AIMessage(content=\"Hello! How can I help you today? Let's have a nice conversation. If you need any calculations, I can do that too! ðŸ˜Š\", additional_kwargs={}, response_metadata={'model': 'mistral-nemo', 'created_at': '2025-03-15T20:58:08.533286Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4515353959, 'load_duration': 617177417, 'prompt_eval_count': 263, 'prompt_eval_duration': 3137000000, 'eval_count': 32, 'eval_duration': 759000000, 'message': Message(role='assistant', content=\"Hello! How can I help you today? Let's have a nice conversation. If you need any calculations, I can do that too! ðŸ˜Š\", images=None, tool_calls=None)}, id='run-5b14021e-fbe7-4626-ba5c-aee5d59ba529-0', usage_metadata={'input_tokens': 263, 'output_tokens': 32, 'total_tokens': 295})}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newsagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
