{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=MODEL, \n",
    "    temperature=TEMPERATURE,\n",
    "    # base_url=\"http://host.docker.internal:11434\", # if running in the studio\n",
    "    ).bind_tools(tools)\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    claim: str\n",
    "    evidence: list[dict]  # {'name': tool name, 'args': {kwargs}, 'result': str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load the autoreload extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# Set autoreload to automatically reload all modules\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "import importlib\n",
    "import os\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, ToolMessage, SystemMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo-0125\"\n",
    "TEMPERATURE = 0\n",
    "# load_dotenv('../.env', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.agents import Tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Define a lookup function that interacts with the external API\n",
    "def remote_api_look_up(query: str, api_key: str, url: str):\n",
    "    # Construct the API query (example using New York Times API)\n",
    "    response = requests.get(f\"{url}?q={query}&api-key={api_key}\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Return the JSON data from the API response\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}\"\n",
    "\n",
    "\n",
    "# Initialize the tool that will call the lookup function\n",
    "def api_lookup_tool(query: str):\n",
    "    # Set your New York Times API details\n",
    "    url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json\"\n",
    "    api_key = \"YOUR_API_KEY_HERE\"  # Replace with your actual API key\n",
    "    \n",
    "    # Call the lookup function\n",
    "    return nyt_lookup(query, api_key, url)\n",
    "\n",
    "\n",
    "tool = Tool(\n",
    "        name=\"NYT_Search_Tool\",\n",
    "        func=api_lookup_tool,\n",
    "        description=\"Searches the New York Times API for articles.\"\n",
    "    )\n",
    "from tools.calculator import add, divide\n",
    "add = Tool(name = \"add\", func = add, description=\"Add `a` and `b`\")\n",
    "divide = Tool(name = \"devide\", func =divide, description=\"Divide `a` and `b`\")\n",
    "tools = [tool,add,divide]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent result: {'input': 'Can you get information about a news article at https://example.com/news-article?', 'output': ''}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname('__file__'), '../..')))\n",
    "from core.agents.tools.remote_tool import remote_tool_func\n",
    "from langchain.agents import Tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "tool = Tool(\n",
    "    name=\"NewsAPI\",\n",
    "    func=remote_tool_func,\n",
    "    description=\"Get information about a news article from a URL\"\n",
    ")\n",
    "\n",
    "tools = [tool]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Use the tools provided to answer the user's question.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{agent_scratchpad}\")\n",
    "])\n",
    "\n",
    "model = ChatOllama(model=\"mistral-nemo\", temperature=0)\n",
    "\n",
    "agent = create_openai_tools_agent(model, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "result = agent_executor.invoke({\"input\": \"Can you get information about a news article at https://example.com/news-article?\"})\n",
    "\n",
    "print(f\"Agent result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=MODEL, \n",
    "    temperature=TEMPERATURE,\n",
    "    # base_url=\"http://host.docker.internal:11434\", # if running in the studio\n",
    "    ).bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    claim: str\n",
    "    evidence: list[dict]  # {'name': tool name, 'args': {kwargs}, 'result': str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "\n",
    "with open('prompts/research_agent_system_prompt.txt', 'r') as f:\n",
    "    sys_msg = SystemMessage(content=f.read())\n",
    "\n",
    "def preprocessing(state: State):\n",
    "    \"\"\"\n",
    "    Preprocesses state before sending to the assistant for tool routing.\n",
    "    Currently, this just extracts the claim from the state and sets it as a HumanMessage\n",
    "    following the SystemMessage\n",
    "    \"\"\"\n",
    "    return {\"messages\": HumanMessage(content=state['claim'])}\n",
    "\n",
    "def assistant(state: State) -> State:\n",
    "    response = llm.invoke(state['messages'])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def postprocessing(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Scan the message history to extract tool calls and results into tuples:\n",
    "    (tool_name, tool_args, tool_result) for the 'evidence' list in the state\n",
    "    \"\"\"\n",
    "    \n",
    "    evidence = []\n",
    "    for i in range(len(state['messages'])):\n",
    "        message = state['messages'][i]\n",
    "        if isinstance(message, AIMessage) and hasattr(message, 'tool_calls'):\n",
    "            for tool_call in message.tool_calls:\n",
    "                # Scan later messages for the corresponding ToolMessage\n",
    "                for j in range(i + 1, len(state['messages'])):\n",
    "                    next_message = state['messages'][j]\n",
    "                    if isinstance(next_message, ToolMessage) and next_message.tool_call_id == tool_call['id']:\n",
    "                        # Found the corresponding ToolMessage\n",
    "                        evidence.append({\n",
    "                            'name': tool_call['name'], \n",
    "                            'args': tool_call['args'], \n",
    "                            'result': next_message.content})\n",
    "                        break\n",
    "\n",
    "    return {'evidence': evidence}\n",
    "    # return state\n",
    "\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"preprocessing\", preprocessing)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_node(\"postprocessing\", postprocessing)\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"preprocessing\")\n",
    "builder.add_edge(\"preprocessing\", \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    source=\"assistant\",\n",
    "    path=tools_condition,\n",
    "    path_map={'tools': 'tools', '__end__': 'postprocessing'}\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "builder.add_edge(\"postprocessing\", END)\n",
    "\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Show\n",
    "# display(Image(react_graph.get_graph(xray=False).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.messages import HumanMessage, SystemMessage\n",
    "claim = \"1/3 is bigger than 1/4.\"\n",
    "# initial_state = {\"claim\": claim}\n",
    "# final_state = graph.invoke(initial_state)\n",
    "\n",
    "messages = [sys_msg]\n",
    "messages = react_graph.invoke({\"messages\": messages, \"claim\": claim})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are an **Evidence Retrieval Agent**. Your role is to retrieve supporting or contradictory evidence for a given claim using the tools available to you.  \n",
      "\n",
      "### **Rules:**  \n",
      "1. **Do Not Evaluate the Claim** – Your task is to retrieve evidence, not to judge the claim's truth.  \n",
      "2. **Select and Use Tools Strategically** – Based on the claim, think carefully which tools would help, and construct the correct tool calls to retrieve relevant evidence.  \n",
      "3. **Return Only Tool Messages** – Your output should consist solely of tool calls with properly structured arguments. Do not generate natural language explanations.  \n",
      "4. **Handle Ambiguity Thoughtfully** – If the claim is unclear, attempt a best-guess search or request clarification through a tool call if applicable.  \n",
      "5. **Retrieve Evidence from Multiple Perspectives** – If conflicting evidence exists, return both supporting and contradictory sources.  \n",
      "\n",
      "### **Behavior:**  \n",
      "- Use available tools efficiently to retrieve the most relevant information.  \n",
      "- Use numeric tools such as calculators for numeric claims\n",
      "- Do not summarize, interpret, or filter the evidence—simply retrieve and present it through tool calls.  \n",
      "\n",
      "Your sole function is to query tools and return raw evidence. You do not form conclusions or engage in reasoning about the claim.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "1/3 is bigger than 1/4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  query (e5d05507-9826-4647-9c62-0485a24e75c5)\n",
      " Call ID: e5d05507-9826-4647-9c62-0485a24e75c5\n",
      "  Args:\n",
      "    query: Compare the sizes of fractions 1/3 and 1/4.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: query\n",
      "\n",
      "No Wikipedia page found for 'Compare the sizes of fractions 1/3 and 1/4.'.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To compare the sizes of two fractions, we can convert them to decimal form or find a common denominator.\n",
      "\n",
      "For 1/3:\n",
      "1 ÷ 3 = 0.333...\n",
      "\n",
      "For 1/4:\n",
      "1 ÷ 4 = 0.25\n",
      "\n",
      "Comparing these decimals, we see that 0.333... is greater than 0.25. Therefore, 1/3 is bigger than 1/4.\n"
     ]
    }
   ],
   "source": [
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'claim': '1/3 is bigger than 1/4.',\n",
      " 'evidence': [{'args': {'query': 'Compare the sizes of fractions 1/3 and 1/4.'},\n",
      "               'name': 'query',\n",
      "               'result': \"No Wikipedia page found for 'Compare the sizes of \"\n",
      "                         \"fractions 1/3 and 1/4.'.\"}],\n",
      " 'messages': [SystemMessage(content=\"You are an **Evidence Retrieval Agent**. Your role is to retrieve supporting or contradictory evidence for a given claim using the tools available to you.  \\n\\n### **Rules:**  \\n1. **Do Not Evaluate the Claim** – Your task is to retrieve evidence, not to judge the claim's truth.  \\n2. **Select and Use Tools Strategically** – Based on the claim, think carefully which tools would help, and construct the correct tool calls to retrieve relevant evidence.  \\n3. **Return Only Tool Messages** – Your output should consist solely of tool calls with properly structured arguments. Do not generate natural language explanations.  \\n4. **Handle Ambiguity Thoughtfully** – If the claim is unclear, attempt a best-guess search or request clarification through a tool call if applicable.  \\n5. **Retrieve Evidence from Multiple Perspectives** – If conflicting evidence exists, return both supporting and contradictory sources.  \\n\\n### **Behavior:**  \\n- Use available tools efficiently to retrieve the most relevant information.  \\n- Use numeric tools such as calculators for numeric claims\\n- Do not summarize, interpret, or filter the evidence—simply retrieve and present it through tool calls.  \\n\\nYour sole function is to query tools and return raw evidence. You do not form conclusions or engage in reasoning about the claim.\", additional_kwargs={}, response_metadata={}, id='370548b9-e170-4163-9fbd-1ed011e734be'),\n",
      "              HumanMessage(content='1/3 is bigger than 1/4.', additional_kwargs={}, response_metadata={}, id='d042aa24-ad9b-4339-b5af-c69f002cbe21'),\n",
      "              AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'mistral-nemo', 'created_at': '2025-03-15T18:17:03.328178Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2344843000, 'load_duration': 27614750, 'prompt_eval_count': 547, 'prompt_eval_duration': 1509000000, 'eval_count': 33, 'eval_duration': 805000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-c85ce358-e334-4aee-8ee5-fa0c2e43f2d6-0', tool_calls=[{'name': 'query', 'args': {'query': 'Compare the sizes of fractions 1/3 and 1/4.'}, 'id': 'e5d05507-9826-4647-9c62-0485a24e75c5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 547, 'output_tokens': 33, 'total_tokens': 580}),\n",
      "              ToolMessage(content=\"No Wikipedia page found for 'Compare the sizes of fractions 1/3 and 1/4.'.\", name='query', id='dd7e1db8-9f8d-412e-96d6-bf28b3aec30b', tool_call_id='e5d05507-9826-4647-9c62-0485a24e75c5'),\n",
      "              AIMessage(content='To compare the sizes of two fractions, we can convert them to decimal form or find a common denominator.\\n\\nFor 1/3:\\n1 ÷ 3 = 0.333...\\n\\nFor 1/4:\\n1 ÷ 4 = 0.25\\n\\nComparing these decimals, we see that 0.333... is greater than 0.25. Therefore, 1/3 is bigger than 1/4.', additional_kwargs={}, response_metadata={'model': 'mistral-nemo', 'created_at': '2025-03-15T18:17:06.11906Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2590695208, 'load_duration': 31516291, 'prompt_eval_count': 76, 'prompt_eval_duration': 252000000, 'eval_count': 98, 'eval_duration': 2305000000, 'message': Message(role='assistant', content='To compare the sizes of two fractions, we can convert them to decimal form or find a common denominator.\\n\\nFor 1/3:\\n1 ÷ 3 = 0.333...\\n\\nFor 1/4:\\n1 ÷ 4 = 0.25\\n\\nComparing these decimals, we see that 0.333... is greater than 0.25. Therefore, 1/3 is bigger than 1/4.', images=None, tool_calls=None)}, id='run-34f137c7-c60a-48e3-ab5f-1b3494deeebc-0', usage_metadata={'input_tokens': 76, 'output_tokens': 98, 'total_tokens': 174})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content=\"No Wikipedia page found for 'Compare the sizes of fractions 1/3 and 1/4.'.\", name='query', id='dd7e1db8-9f8d-412e-96d6-bf28b3aec30b', tool_call_id='e5d05507-9826-4647-9c62-0485a24e75c5')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = react_graph.nodes['assistant'].invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"hi there\")]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': AIMessage(content=\"Hello! How can I help you today? Let's have a nice conversation. If you need any calculations, I can do that too! 😊\", additional_kwargs={}, response_metadata={'model': 'mistral-nemo', 'created_at': '2025-03-15T20:58:08.533286Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4515353959, 'load_duration': 617177417, 'prompt_eval_count': 263, 'prompt_eval_duration': 3137000000, 'eval_count': 32, 'eval_duration': 759000000, 'message': Message(role='assistant', content=\"Hello! How can I help you today? Let's have a nice conversation. If you need any calculations, I can do that too! 😊\", images=None, tool_calls=None)}, id='run-5b14021e-fbe7-4626-ba5c-aee5d59ba529-0', usage_metadata={'input_tokens': 263, 'output_tokens': 32, 'total_tokens': 295})}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
