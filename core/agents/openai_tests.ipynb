{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a1f0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is set\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('../.env', override=True)\n",
    "if os.getenv('OPENAI_API_KEY') is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable not set\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY is set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4985f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "    # base_url=\"...\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "sys_msg = SystemMessage(\n",
    "    content=\"You are a helpful assistant that speaks like Shakespeare.\"\n",
    ")\n",
    "human_msg = HumanMessage(\n",
    "    content=\"What is the capital of France?\"\n",
    ")\n",
    "messages = [sys_msg, human_msg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f626285d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The capital of France, good sir or madam, is Paris.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 28, 'total_tokens': 43, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f5bdcc3276', 'id': 'chatcmpl-BWQMWOShChCkxQ7F31qr7j9wkfVY8', 'finish_reason': 'stop', 'logprobs': None} id='run-228b0403-4866-490d-bb76-011e4b96759c-0' usage_metadata={'input_tokens': 28, 'output_tokens': 15, 'total_tokens': 43, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19916c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699155c6",
   "metadata": {},
   "source": [
    "## Test builtin tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ef780e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "name='wikipedia' description='Query wiki. Use it to get factual information on: \\n- historical figures, events, or places\\n- scientific concepts\\n- common knowledge\\n- debunked myths' args_schema=<class 'langchain_core.utils.pydantic.wikipedia'> response_format='content_and_artifact' func=<function tool_function at 0x1162bc180>\n"
     ]
    }
   ],
   "source": [
    "from core.agents.tools.builtins.wikipedia_tool import tool_function as wikipedia\n",
    "print(type(wikipedia))\n",
    "print(wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca881c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([wikipedia])\n",
    "sys_msg_tools = SystemMessage(\n",
    "    content=\"You are a helpful research assistant that can use Wikipedia.\"\n",
    ")\n",
    "response_from_tools = llm_with_tools.invoke([sys_msg_tools, human_msg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec79a70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_qZEUwpLeGOkbsoPtwYYG7ssE', 'function': {'arguments': '{\"query_str\":\"capital of France\"}', 'name': 'wikipedia'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 100, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f5bdcc3276', 'id': 'chatcmpl-BWQQBNTkob2dB98x0XRs6shk1c2Gg', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-0876c5bd-4cf6-4c24-881e-b7a6c76749e7-0' tool_calls=[{'name': 'wikipedia', 'args': {'query_str': 'capital of France'}, 'id': 'call_qZEUwpLeGOkbsoPtwYYG7ssE', 'type': 'tool_call'}] usage_metadata={'input_tokens': 100, 'output_tokens': 17, 'total_tokens': 117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(response_from_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0281a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.agents.tools.builtins.calculator import tool_function as calculator\n",
    "from core.agents.tools.builtins.web_search import tool_function as web_search\n",
    "llm_with_tools = llm.bind_tools([wikipedia, calculator, web_search])\n",
    "sys_msg_tools = SystemMessage(\n",
    "    content=\"You are a helpful research assistant that can use Wikipedia, a calculator, and web search.\"\n",
    ")\n",
    "human_msg = HumanMessage(\n",
    "    content=\"What is the capital of France? What is 2 + 2? What is the weather like today in NYC?\"\n",
    ")\n",
    "response = llm_with_tools.invoke([sys_msg_tools, human_msg])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6c6d67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "[{'args': {'query_str': 'capital of France'},\n",
      "  'id': 'call_tkbgzuEyiuWAs9wPhei622u3',\n",
      "  'name': 'wikipedia',\n",
      "  'type': 'tool_call'},\n",
      " {'args': {'expression': '2 + 2'},\n",
      "  'id': 'call_FTtuCCXh4GGiQ7oqn9BWJMK7',\n",
      "  'name': 'calculator',\n",
      "  'type': 'tool_call'},\n",
      " {'args': {'query': 'weather today in NYC', 'topic': 'news'},\n",
      "  'id': 'call_iFcOr8ibYXjEN2DJUBAzDlbt',\n",
      "  'name': 'web_search',\n",
      "  'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(type(response))\n",
    "pprint(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e5c7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newsagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
