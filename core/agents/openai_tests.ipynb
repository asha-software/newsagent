{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a1f0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is set\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('../.env', override=True)\n",
    "if os.getenv('OPENAI_API_KEY') is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable not set\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY is set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda1366",
   "metadata": {},
   "source": [
    "# Testing common interface on `ChatOpenAI` and `ChatOllama` models returned by the `llm_factory`\n",
    "1. Getting basic prompt completions\n",
    "1. Returning structured output with Pydantic models\n",
    "1. Using builtin tools\n",
    "1. Using custom tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4985f6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model 'gpt-4.1' with structured output model 'None'\n",
      "content='Verily, good sir or madam, the capital of France is Paris, that fair and noble city oft called the City of Light.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 28, 'total_tokens': 57, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_beec22d258', 'id': 'chatcmpl-BWX2knVVtU3F6crcWHPo2PnOrpwnP', 'finish_reason': 'stop', 'logprobs': None} id='run-d1ef7791-5b80-4719-9d38-70a16be899a9-0' usage_metadata={'input_tokens': 28, 'output_tokens': 29, 'total_tokens': 57, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from core.agents.utils.llm_factory import get_chat_model\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "sys_msg = SystemMessage(\n",
    "    content=\"You are a helpful assistant that speaks like Shakespeare.\"\n",
    ")\n",
    "human_msg = HumanMessage(\n",
    "    content=\"What is the capital of France?\"\n",
    ")\n",
    "messages = [sys_msg, human_msg]\n",
    "\n",
    "openai_llm = get_chat_model(model_name=\"gpt-4.1\")\n",
    "response = openai_llm.invoke(messages)\n",
    "print(response)\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae7d862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model 'mistral-nemo' with structured output model 'None'\n",
      "content='Verily, the capital of France is Paris, a city of great renown and beauty, where the Seine doth flow through its heart.' additional_kwargs={} response_metadata={'model': 'mistral-nemo', 'created_at': '2025-05-12T23:40:19.957198Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2167563542, 'load_duration': 1144584583, 'prompt_eval_count': 20, 'prompt_eval_duration': 334111916, 'eval_count': 30, 'eval_duration': 687944917, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-042e5092-d121-4910-aa3b-2ffbac238432-0' usage_metadata={'input_tokens': 20, 'output_tokens': 30, 'total_tokens': 50}\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "ollama_llm = get_chat_model(model_name=\"mistral-nemo\")\n",
    "ollama_response = ollama_llm.invoke(messages)\n",
    "print(ollama_response)\n",
    "print(type(ollama_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1765b0a5",
   "metadata": {},
   "source": [
    "### Chat completion results: \n",
    "Both respond with an `AIMessage` when no tools bound or structured output instructions\n",
    "\n",
    "## Test Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30744368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model 'gpt-4o' with structured output model '<class '__main__.ClaimsOutput'>'\n",
      "<class '__main__.ClaimsOutput'>\n",
      "claims=['The Apollo 11 mission landed humans on the Moon for the first time on July 20, 1969.', 'Neil Armstrong was the first person to walk on the lunar surface.', 'The Apollo 11 mission was launched by NASA using a Saturn V rocket.']\n",
      "<class 'list'>\n",
      "['The Apollo 11 mission landed humans on the Moon for the first time on July 20, 1969.', 'Neil Armstrong was the first person to walk on the lunar surface.', 'The Apollo 11 mission was launched by NASA using a Saturn V rocket.']\n"
     ]
    }
   ],
   "source": [
    "class ClaimsOutput(BaseModel):\n",
    "    claims: list[str] = Field(description=\"The list of individual claim strings.\")\n",
    "\n",
    "openai_structured_llm = get_chat_model(\n",
    "    model_name=\"gpt-4o\",\n",
    "    output_model=ClaimsOutput\n",
    ")\n",
    "\n",
    "with open('prompts/claim_decomposer_system_prompt.txt', 'r') as f:\n",
    "    claim_decomposer_system_prompt = f.read()\n",
    "\n",
    "cd_system_prompt = SystemMessage(\n",
    "    content=claim_decomposer_system_prompt\n",
    ")\n",
    "text = \"\"\"\n",
    "The Apollo 11 mission landed humans on the Moon for the first time on July 20, 1969.\n",
    "Neil Armstrong was the first person to walk on the lunar surface.\n",
    "The mission was launched by NASA using a Saturn V rocket.\n",
    "\"\"\"\n",
    "human_msg = HumanMessage(content=text)\n",
    "cd_response = openai_structured_llm.invoke([cd_system_prompt, human_msg])\n",
    "print(type(cd_response))\n",
    "print(cd_response)\n",
    "\n",
    "print(type(cd_response.claims))\n",
    "print(cd_response.claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e5c7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model 'mistral-nemo' with structured output model '<class '__main__.ClaimsOutput'>'\n",
      "<class '__main__.ClaimsOutput'>\n",
      "<class 'list'>\n",
      "['The Apollo 11 mission landed humans on the Moon for the first time on July 20, 1969.', 'Neil Armstrong was the first person to walk on the lunar surface.', 'The Apollo 11 mission was launched by NASA using a Saturn V rocket.']\n"
     ]
    }
   ],
   "source": [
    "ollama_structured_llm = get_chat_model(\n",
    "    model_name=\"mistral-nemo\",\n",
    "    output_model=ClaimsOutput\n",
    ")\n",
    "ollama_cd_response = ollama_structured_llm.invoke([cd_system_prompt, human_msg])\n",
    "print(type(ollama_cd_response))\n",
    "print(type(ollama_cd_response.claims))\n",
    "print(ollama_cd_response.claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af1d0f3",
   "metadata": {},
   "source": [
    "### Structured Output Results\n",
    "\n",
    "Both chat models can accept a Pydantic model to structure their outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699155c6",
   "metadata": {},
   "source": [
    "## Test builtin tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca881c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "name='wikipedia' description='Query wiki. Use it to get factual information on: \\n- historical figures, events, or places\\n- scientific concepts\\n- common knowledge\\n- debunked myths' args_schema=<class 'langchain_core.utils.pydantic.wikipedia'> response_format='content_and_artifact' func=<function tool_function at 0x115ae54e0>\n",
      "Using model 'gpt-4o' with structured output model 'None'\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "[{'args': {'query_str': 'capital of France'},\n",
      "  'id': 'call_ZqF9fHaW4kZJe7DQxEFy5x2y',\n",
      "  'name': 'wikipedia',\n",
      "  'type': 'tool_call'},\n",
      " {'args': {'expression': '2 + 2'},\n",
      "  'id': 'call_sLwyDdDgKJVVbuYfm7eH2uX6',\n",
      "  'name': 'calculator',\n",
      "  'type': 'tool_call'},\n",
      " {'args': {'query': 'weather today in NYC', 'topic': 'news'},\n",
      "  'id': 'call_7m0m3r49zUjdPzFHF7FC8r7N',\n",
      "  'name': 'web_search',\n",
      "  'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from core.agents.tools.builtins.web_search import tool_function as web_search\n",
    "from core.agents.tools.builtins.calculator import tool_function as calculator\n",
    "from core.agents.tools.builtins.wikipedia_tool import tool_function as wikipedia\n",
    "print(type(wikipedia))\n",
    "print(wikipedia)\n",
    "\n",
    "llm_with_tools = get_chat_model(model_name=\"gpt-4o\").bind_tools([wikipedia, web_search, calculator])\n",
    "sys_msg_tools = SystemMessage(\n",
    "    content=\"You are a helpful research assistant that can use Wikipedia, a calculator, and web search.\"\n",
    ")\n",
    "human_msg = HumanMessage(\n",
    "    content=\"What is the capital of France? What is 2 + 2? What is the weather like today in NYC?\"\n",
    ")\n",
    "response = llm_with_tools.invoke([sys_msg_tools, human_msg])\n",
    "\n",
    "print(type(response))\n",
    "pprint(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6701bc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model 'mistral-nemo' with structured output model 'None'\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "[{'args': {'query_str': 'Capital of France'},\n",
      "  'id': '6891027a-6b71-4b98-b7f6-35ed1c613665',\n",
      "  'name': 'wikipedia',\n",
      "  'type': 'tool_call'},\n",
      " {'args': {'expression': '2+2'},\n",
      "  'id': '75b9425d-bf14-491c-afde-6fbba5bc9e60',\n",
      "  'name': 'calculator',\n",
      "  'type': 'tool_call'},\n",
      " {'args': {'query': \"Today's weather in NYC\", 'topic': 'general'},\n",
      "  'id': '56940531-0d0f-44bd-be5a-941414d010d2',\n",
      "  'name': 'web_search',\n",
      "  'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "ollama_with_tools = get_chat_model(model_name=\"mistral-nemo\").bind_tools([wikipedia, web_search, calculator])\n",
    "ollama_response = ollama_with_tools.invoke([sys_msg_tools, human_msg])\n",
    "print(type(ollama_response))\n",
    "pprint(ollama_response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70491878",
   "metadata": {},
   "source": [
    "### Builtin tool conclusion:\n",
    "Both ChatOpenAI and ChatOllama can have the builtin tools bound to them and produce correct tool calls\n",
    "\n",
    "## Custom Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ea3af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "name='pokeapi' description=\"Get information about a Pokémon from the PokeAPI.\\n    Args:\\n        name (str): The name of the Pokémon to query, ALWAYS LOWERCASED.\\n    Returns:\\n        list: A list containing the Pokémon's abilities.\" args_schema={'type': 'object', 'properties': {'name': {'description': 'name parameter', 'type': 'string'}}, 'required': ['name']} response_format='content_and_artifact' func=<function create_tool.<locals>.tool_function at 0x1160167a0>\n",
      "Using model 'gpt-4o' with structured output model 'None'\n"
     ]
    }
   ],
   "source": [
    "from core.agents.tools.tool_registry import create_tool\n",
    "\n",
    "pokemon_kwargs = {\n",
    "    'name': 'pokeapi',\n",
    "    'method': 'GET',\n",
    "    'headers': {'Accept': 'application/json'},\n",
    "    'url_template': 'https://pokeapi.co/api/v2/pokemon/{name}',\n",
    "    'docstring': '''Get information about a Pokémon from the PokeAPI.\n",
    "    Args:\n",
    "        name (str): The name of the Pokémon to query, ALWAYS LOWERCASED.\n",
    "    Returns:\n",
    "        list: A list containing the Pokémon's abilities.\n",
    "    ''',\n",
    "    'target_fields': [['abilities', 0, 'ability', 'name'],\n",
    "                      ['abilities', 1, 'ability', 'name']],\n",
    "    'param_mapping': {\n",
    "            'name': {\n",
    "                'type': 'str',\n",
    "                'for': 'url_params'\n",
    "            }\n",
    "    },\n",
    "}\n",
    "\n",
    "pokemon_tool = create_tool(**pokemon_kwargs)\n",
    "print(type(pokemon_tool))\n",
    "print(pokemon_tool)\n",
    "pokemon_openai_llm = get_chat_model(model_name=\"gpt-4o\").bind_tools([pokemon_tool])\n",
    "\n",
    "with open('prompts/research_agent_system_prompt.txt', 'r') as f:\n",
    "    research_agent_system_prompt = f.read()\n",
    "sys_msg = SystemMessage(content=research_agent_system_prompt)\n",
    "human_msg = HumanMessage(\n",
    "    content=\"Pikachu has electric abilities\"\n",
    ")\n",
    "\n",
    "response = pokemon_openai_llm.invoke([sys_msg, human_msg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5985e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_gAWcwiSATgd3q9Cl8aePLnLy', 'function': {'arguments': '{\"name\":\"pikachu\"}', 'name': 'pokeapi'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 832, 'total_tokens': 849, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f5bdcc3276', 'id': 'chatcmpl-BWX30OF5r86ZgBZrtIAttjKChafv6', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-b53cecf6-d6d4-475b-b982-77aede21aa3f-0' tool_calls=[{'name': 'pokeapi', 'args': {'name': 'pikachu'}, 'id': 'call_gAWcwiSATgd3q9Cl8aePLnLy', 'type': 'tool_call'}] usage_metadata={'input_tokens': 832, 'output_tokens': 17, 'total_tokens': 849, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "[{'name': 'pokeapi', 'args': {'name': 'pikachu'}, 'id': 'call_gAWcwiSATgd3q9Cl8aePLnLy', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response)\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae6e9115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model 'mistral-nemo' with structured output model 'None'\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='' additional_kwargs={} response_metadata={'model': 'mistral-nemo', 'created_at': '2025-05-12T23:40:35.137783Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2892786458, 'load_duration': 28102292, 'prompt_eval_count': 894, 'prompt_eval_duration': 2250531208, 'eval_count': 24, 'eval_duration': 609932959, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-aec052ac-f501-4e92-b4c4-1ea89e950160-0' tool_calls=[{'name': 'pokeapi', 'args': {'name': 'pikachu'}, 'id': '2ab15d1e-2487-40d8-91b7-b61f24f74b44', 'type': 'tool_call'}] usage_metadata={'input_tokens': 894, 'output_tokens': 24, 'total_tokens': 918}\n",
      "[{'name': 'pokeapi', 'args': {'name': 'pikachu'}, 'id': '2ab15d1e-2487-40d8-91b7-b61f24f74b44', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "pokemon_ollama_llm = get_chat_model(model_name=\"mistral-nemo\").bind_tools([pokemon_tool])\n",
    "ollama_response = pokemon_ollama_llm.invoke([sys_msg, human_msg])\n",
    "print(type(ollama_response))\n",
    "print(ollama_response)\n",
    "print(ollama_response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca4a7f4",
   "metadata": {},
   "source": [
    "### Custom tools results\n",
    "\n",
    "Both ChatOpenAI and ChatOllama can implement custom tools through the tool registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4766e74",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855308ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newsagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
